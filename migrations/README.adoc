= Fusion 5 Migration Guide
:toc:
:toclevels: 5
:toc-title:

The latest version of Fusion 5 is 5.3.x. The migration process varies depending on your current version of Fusion.

// tag::body[]

== Migration from Fusion 5.4.x to 5.8.x

The migration steps are required for Solr upgrade to version 9.1.x.

==== Prerequisites

Make sure solr is running and all collections are healthy.

Current solr version is higher than 8.2.x.

For production systems, this upgrade process should be performed during a maintenance window.
Always test the migration on pre-production environment with the exact copy of production application.

Operation *must* be performed before the Solr is upgraded. Upgrading the solr with not migrated collection will prevent them to load.

If currently used collection are not using the default solr configuration which is shipped with Fusion it may not require an update may cause some malfunctions or there maybe needed an additional steps .

==== Application migration process

===== Manual steps

For all the solr collections perform:

* Edit `solrconfig.xml`:
** In caches elements ("filterCache", "cache", "documentCache", "queryResultCache") check if `class` attribute is either empty or set to `solr.search.CaffeineCache`.
** From all `requestHandler/lst` elements remove the element `<bool..>` with attribute `name='preferLocalShards'`
** Remove queryResponseWriter of class `solr.XSLTResponseWriter`
** Remove `circuitBreaker` elements which doesn't have a class attribute
* Edit `managed-schema` file:
** remove attribute `keepShortTerm` from all analyzers of class `solr.NGramFilterFactory`

===== Migration tool

Lucidworks provides the utility docker image with the script to automate the required collection configuration update.

The best way is to export the existing application to zip file and run the migration on it.
Assuming that you are in the directory where you have exported the app with the name `exported-app.zip`, run:
```
 docker run --rm -v $(pwd):/apps -e INPUT_FILE=/apps/exported-app.zip lucidworks/fm-upgrade-to-solr-9:1.1.0
```

This will generate the migrated application with name `exported-app-migrated.zip`. Check the output for any _WARNINGS_ and _ERRORS_.

==== How to fix the solr after importing not migrated application

If you have upgraded the solr without migration the collection configuration first, collection will not start, and you will not be able to access it.

* If collection have some data, the best approach is revert the solr from backup.
* If you cannot use backup, then:
** shutdown solr
** export the application from other Fusion instance
** migrate the application
** you need to manually replace the configuration of each collection with its migrated version in Zookeeper's `/configs/` node.
** restart solr nodes
* If you have just imported not migrated application:
** remove the application
** manually remove collections configuration from `/configs/` node in Zookeeper (remove only configs which belongs to application you have removed, not all)
** restart *all* solr nodes
** migrate the application
** import migrated application

== Migration from Fusion 5.4.x to 5.5.x

==== Prerequisites

Make sure solr is running and all collections are healthy

For production systems, this upgrade process should be performed during a maintenance window.

Described operation is changing the solrconfig.xml of all collections in Solr instances. If there are collections not managed by Fusion system in Solr, they also can be affected.

Current solr version is higher than 8.2.x.

Operation can be performed before the Fusion upgrade or after it.

If currently used collection are not using the default solr configuration which is shipped with Fusion it may not require an update or update may cause some malfunctions.

==== Update cache's settings in Solr collections

Lucidworks provides the utility docker image with the script to automate the required collections configuration update.

```
kubectl run --image="lucidworks/fm-upgrade-solrconfig-cache:1.0.0" \
  -n<namespace> \
  --env="HELM_RELEASE=<release_name>" \
  --labels='app.kubernetes.io/component=solr-backup-runner'
  --env="DRY_RUN=false" \
  fm-upgrade-solrconfig-cache
```

Set `DRY_RUN=true` if you want to just see what will be affected without applying any changes to system. Check logs:
```
kubectl -n<namespace> logs -f fm-upgrade-solrconfig-cache
```

After updated is done, remove the pod:
```
kubectl -n<namespace> delete pod fm-upgrade-solrconfig-cache
```
Instead of providing `HELM_RELEASE` name from which scripts infer the Solr sever name, you can use direct url with `SOLR` variable: `--env="SOLR=http://server:8983"`.

This method will create a `configoverlay.json` file in config directory with modified collection. It will contain all required changes which applied by solr on `solrconfig.xml`.

Second way you can use the image, is to convert exported apps. To do this you first need to export the app from existing system and place in local system, where docker is installed.

Assuming that in current directory there is an `exported-app.zip`, you can run
```
 docker run --rm -v $(pwd):/apps -e INPUT_FILE=/apps/exported-app.zip lucidworks/fm-upgrade-solrconfig-cache:1.0.0
```

This command will produce the `exported-app-migrated.zip` in current directory. This method will directly modify the `solrconfig.json` file, without creating `configoverlay.json`.

== Migration from Fusion 5.3.x to 5.4.0

==== Prerequisites

Make sure you're fusion admin is running and all collections are healthy

You *should not* be actively making changes to the `signals` collections (via Rules UI) during the upgrade process.

For production systems, this upgrade process should be performed during a maintenance window.

===== Update signal collections solr config

Lucidworks recommends taking a backup of your signal collections just in case something goes wrong with the upgrade, especially for production environments.

Depending on your Ingress config, the export may take too long and timeout. Consequently, we recommend opening a `kubectl` port-forward to the Fusion Gateway pod:
```
kubectl port-forward <POD> 6764
```

Run the below commands in the terminal or update the creds in the update_signal_collection.sh and run ./update_signal_collection.sh
```
PROXY="http://localhost:6764"
APP="YOUR_FUSION_APP_ID"
curl -u $CREDS -X POST "$PROXY/api/update/all/signalCollection"
```
__Replace `$CREDS` with your Fusion admin username and password__, for example `-u admin:somepassword`

Once the script is executed, verify all collections are healthy. Check fusion-admin pod logs for any errors.

===== Update Connectors services names

In Fusion 5.4.0 we introduced name changes to some services related to connectors.
```
connector-plugin-service -> connector-plugin
rest-service -> connectors
rpc-service -> connectors-backend
```

Make sure to update your `*_values.yaml` replacing old names.

== Migrating from Fusion 5.2.x to 5.3.x
// tag::521-to-530[]

Lucene 8.4.1 introduced an incompatible change to the underlying `postingsFormat` for the `tagger` field type in the schema for query_rewrite collections.
For additional background on the Solr text tagger and the `FST50` postings format, see: https://lucene.apache.org/solr/guide/8_3/the-tagger-handler.html[the Solr documentation^].

Consequently, before you upgrade to Solr 8.6.3, you need to re-index the `query_rewrite` documents to remove the use of the `postingsFormat`.
Otherwise, when Solr 8.6.3 initializes, it will not be able to load the `query_rewrite` collections.
After upgrading, you'll re-index once again to restore the `postingsFormat` using the new implementation; the custom `postingsFormat` is essential for achieving optimal text tagging performance.

==== Prerequisites

Make sure you're running on Solr 8.4.1 and that all collections are healthy.

You *should not* be actively making changes to the `query_rewrite` collections (via Rules UI) during the upgrade process.

For production systems, this upgrade process should be performed during a maintenance window.

===== Back up the query_rewrite and query_rewrite_staging collections

Lucidworks recommends taking a backup of your query rewrite collections just in case something goes wrong with the upgrade, especially for production environments.

Depending on your Ingress config, the export may take too long and timeout. Consequently, we recommend opening a `kubectl` port-forward to the Fusion Gateway pod:
```
kubectl port-forward <POD> 6764
```

Then export the collection(s) to a local JSON file using the `/query/query-rewrite/export/<COLL>` endpoint. For instance:
```
PROXY="http://localhost:6764"
APP="YOUR_FUSION_APP_ID"
curl -u $CREDS "$PROXY/query/query-rewrite/export/${APP}_query_rewrite_staging" > ${APP}_query_rewrite_staging.json
curl -u $CREDS "$PROXY/query/query-rewrite/export/${APP}_query_rewrite" > ${APP}_query_rewrite.json
```
__Replace `$CREDS` with your Fusion admin username and password__, for example `-u admin:somepassword`

Repeat this command for *every Fusion application* that has data indexed in the `query_rewrite_staging` and `query_rewrite` collections.


==== Upgrade Steps

In order to upgrade from Solr 8.4.1 to 8.6.3, you need to re-index all `query_rewrite` and `query_rewrite_staging` collections that have indexed data.

Lucidworks provides a utility Docker image to drive the re-index process.

If your installation does not have indexed documents in any of the `query_rewrite` collections, then you can safely upgrade to Solr 8.6.3 using a Helm upgrade.

. Run the *prepare* step.
+
The *prepare* step re-indexes the query_rewrite collections into a temp collection after removing the `postingsFormat` from the `tagger` field type in the Solr schema.
This ensures the temp collections can be restored when Solr 8.6.3 initializes.
+
```
kubectl run --generator=run-pod/v1 \
  --image="lucidworks/fm-upgrade-query-rewrite:2.x" \
  --restart=Never \
  --env="HELM_RELEASE=<CHANGEME>" \
  --env="TARGET_SOLR_VERSION=8.6.3" \
  --env="ACTION=prepare" prepare-upgrade-solr863
```
+
*Be sure to change the HELM_RELEASE value to the release name (NOT the version) of your Fusion 5 installation.* You can find this using `helm list`
against your Fusion 5 namespace (find the release that's using the "fusion" chart and look at the name column). Typically, the
release name is the same as your namespace name.

. Wait until the `prepare-upgrade-solr863` pod shows status `Completed`.

. Upgrade to Solr 8.6.3 using the standard Fusion 5 Helm upgrade process (set the Solr tag version to `8.6.3` in custom values yaml).

. Verify all `*_temp_fix` collections are online and healthy.

. Run the *restore* step.
+
The *restore* step re-indexes the temp collections back into the original `query_rewrite` collections after restoring the `postingsFormat` on the tagger field with the new implementation added in Lucene 8.6.3.
+
```
kubectl run --generator=run-pod/v1 \
  --image="lucidworks/fm-upgrade-query-rewrite:2.x" \
  --restart=Never \
  --env="HELM_RELEASE=<CHANGEME>" \
  --env="TARGET_SOLR_VERSION=8.6.3" \
  --env="ACTION=restore" restore-upgrade-solr863
```
+
*Be sure to change the HELM_RELEASE value to the release name of your Fusion 5 installation.*

. Wait until the `restore-upgrade-solr863` pod shows status `Completed`.

. Verify all query rewrite collections are online and healthy.

. Delete the prepare and restore pods.
+
```
kubectl delete po prepare-upgrade-solr863
kubectl delete po restore-upgrade-solr863
```

// end::521-to-530[]

== Migrating from Fusion 5.1.4 to 5.2.0

In Fusion 5.2.0 logstash has been removed from the deployment, if you were previously using logstash to forward logs to an external cluster please setup
an external logstash instance pointing to this cluster and then add:
```
global:
  logging:
    logstashHost: <logstash_host>
```
to your values file before upgrading by following the link:https://doc.lucidworks.com/how-to/upgrade-fusion-with-helm3.html[Fusion upgrade instructions].  

Please note, it is not currently possible to update an existing cluster enable or disable TLS between services so this cannot be enabled as part of a migration.

== Migrating from Fusion 5.0.x to 5.1.x

If you're currently running Fusion 5.0.2+, then you need to perform three steps before upgrading to 5.1.0. If you are installing Fusion 5.1.0 into a new namespace, then you can safely skip these steps.

If you're currently running Fusion 5.0.0 - 5.0.1, then please follow the <<upgrade-to-502,Upgrade from 5.0.1>> steps before proceeding with this section.

. Prepare Upgrade Solr 8.4.1
. Install Kubernetes Custom Resource Definition (CRDs) for Seldon Core
. Delete the Logstash StatefulSet (only needed for clusters running 5.0.3-2 or earlier)
. Update the Prometheus Scrape Path for query, index, and gateway services

=== Prepare for Upgrade to Solr 8.4.1

Lucene 8.4.1 introduced an incompatible change to the underlying `postingsFormat` for the `tagger` field type in the schema for query_rewrite collections.
For additional background on the Solr text tagger and the `FST50` postings format, see: https://lucene.apache.org/solr/guide/8_3/the-tagger-handler.html

Consequently, before you upgrade to Solr 8.4.1, you need to re-index the query_rewrite documents to remove the use of the `postingsFormat`.
Otherwise, when Solr 8.4.1 initializes, it will not be able to load the query_rewrite collections.
After upgrading, you'll re-index once again to restore the `postingsFormat` using the new implementation; the custom `postingsFormat` is essential for achieving optimal text tagging performance.

==== Prerequisites

Before proceeding, please https://github.com/lucidworks/fusion-cloud-native[follow the upgrade instructions
 corresponding to your cloud platform here] to upgrade your Fusion 5 installation to the latest Helm chart: `5.0.3-4`.

Make sure you're running on Zookeeper 3.5.6 and Solr 8.3.1 and that all collections are healthy.

You *should not* be actively making changes to the `query_rewrite` collections (via Rules UI) during the upgrade process.

For production systems, this upgrade process should be performed during a maintenance window.

===== Backup the query_rewrite and query_rewrite_staging collections

Lucidworks recommends taking a backup of your query rewrite collections just in case something goes wrong with the upgrade, especially for production environments.

Depending on your Ingress config, the export may take too long and timeout. Consequently, we recommend opening a kubectl port-forward to the Fusion Gateway pod:
```
kubectl port-forward <POD> 6764
```

Then export the collection(s) to a local JSON file using the `/query/query-rewrite/export/<COLL>` endpoint. For instance:
```
PROXY="http://localhost:6764"
APP="YOUR_FUSION_APP_ID"
curl -u $CREDS "$PROXY/query/query-rewrite/export/${APP}_query_rewrite_staging" > ${APP}_query_rewrite_staging.json
curl -u $CREDS "$PROXY/query/query-rewrite/export/${APP}_query_rewrite" > ${APP}_query_rewrite.json
```
__Replace `$CREDS` with your Fusion admin username and password__, for example `-u admin:somepassword`

Repeat this command for *every Fusion application* that has data indexed in the `query_rewrite_staging` and `query_rewrite` collections.

==== Upgrade Steps

In order to upgrade from Solr 8.3.1 to 8.4.1, you need to re-index all query_rewrite and query_rewrite_staging collections that have indexed data.

Lucidworks provides a utility Docker image to drive the re-index process.

If your installation does not have indexed documents in any of the `query_rewrite` collections, then you can safely upgrade to Solr 8.4.1 using a Helm upgrade.

1) Run the *prepare* step

The *prepare* step re-indexes the query_rewrite collections into a temp collection after removing the `postingsFormat` from the `tagger` field type in the Solr schema.
This ensures the temp collections can be restored when Solr 8.4.1 initializes.

```
kubectl run --generator=run-pod/v1 \
  --image="lucidworks/fm-upgrade-query-rewrite:1.x" \
  --restart=Never \
  --env="HELM_RELEASE=<CHANGEME>" \
  --env="ACTION=prepare" prepare-upgrade-solr841
```
*Be sure to change the HELM_RELEASE value to the release name (NOT the version) of your Fusion 5 installation.* You can find this using `helm list`
against your Fusion 5 namespace (find the release that's using the "fusion" chart and look at the name column). Typically, the
release name is the same as your namespace name.

Wait until the `prepare-upgrade-solr841` pod shows status `Completed`

2) Upgrade to Solr 8.4.1 using the standard Fusion 5 Helm upgrade process (set the Solr tag version to `8.4.1` in custom values yaml)

3) Verify all `*_temp_fix` collections are online and healthy

4) Run the *restore* step

The *restore* step re-indexes the temp collections back into the original query_rewrite collections after restoring the `postingsFormat` on the tagger field with the new implementation added in Lucene 8.4.1.

```
kubectl run --generator=run-pod/v1 \
  --image="lucidworks/fm-upgrade-query-rewrite:1.x" \
  --restart=Never \
  --env="HELM_RELEASE=<CHANGEME>" \
  --env="ACTION=restore" restore-upgrade-solr841
```
*Be sure to change the HELM_RELEASE value to the release name of your Fusion 5 installation.*

Wait until the `restore-upgrade-solr841` pod shows status `Completed`

5) Verify all query rewrite collections are online and healthy

6) Delete the prepare and restore pods

```
kubectl delete po prepare-upgrade-solr841
kubectl delete po restore-upgrade-solr841
```

=== Install Seldon Core CRD

Fusion 5.1.0 introduces https://www.seldon.io/tech/products/core/[Seldon Core] for ML model serving. Seldon Core installs Kuberentes Custom Resource Definitions (CRD). Due to a limitation in how Helm handles CRDs during upgrades to an existing cluster, you may need to install the CRDs into a temp namespace before attempting an upgrade to your existing namespace.

Check if the Seldon Core CRDs are present in your cluster already
```
kubectl api-versions | grep machinelearning.seldon.io/v1
```
If this returns no results then run the following commands to create a temporary namespace and install the Seldon Core CRDs into the K8s cluster:
```
kubectl create namespace tmp-crd-install
helm install --namespace tmp-crd-install tmp-crd lucidworks/fusion --version 5.1.0 --debug \
  --set "solr.enabled=false" --set "fusion-admin.enabled=false" \
  --set "fusion-indexing.enabled=false" --set "query-pipeline.enabled=false" \
  --set "api-gateway.enabled=false" --set "classic-rest-service.enabled=false" \
  --set "sql-service.enabled=false" --set "zookeeper.enabled=false" \
  --set "job-launcher.enabled=false" --set "job-rest-service.enabled=false" \
  --set "rest-service.enabled=false" --set "rpc-service.enabled=false" \
  --set "logstash.enabled=false" --set "webapps.enabled=false"
helm delete --namespace tmp-crd-install tmp-crd
kubectl delete namespace tmp-crd-install
```

To verify the Seldon Core CRDs were installed successfully, run:
```
k api-versions | grep machinelearning.seldon.io/v1;
```
You should see output like:
```
machinelearning.seldon.io/v1
machinelearning.seldon.io/v1alpha2
machinelearning.seldon.io/v1alpha3
```

=== Delete Logstash StatefulSet

If you're running Fusion `5.0.3-2` or earlier, then you need to delete the Logstash StatefulSet. The data will remain intact and Logstash will be restored correctly during the Fusion upgrade.
```
kubectl delete sts <RELEASE>-logstash
```

You may now proceed to upgrade to Fusion 5.1.0. Be sure to update the `CHART_VERSION` to `5.1.0` in your upgrade script.

=== Update Prometheus Scrape Path

Please add the `prometheus.io/path: "/actuator/prometheus"` annotation to the `api-gateway`, `query-pipeline`, and `fusion-indexing` sections of your custom values yaml:
```
query-pipeline:
  ... existing settings
  pod:
    annotations:
      prometheus.io/port: "8787"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"

api-gateway:
  ... existing settings
  pod:
    annotations:
      prometheus.io/port: "6764"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"

fusion-indexing:
  ... existing settings
  pod:
    annotations:
      prometheus.io/port: "8765"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"
```
Also, we've added a new Grafana dashboard for monitoring Pulsar topic metrics, see: https://github.com/lucidworks/fusion-cloud-native/blob/master/monitoring/grafana/pulsar_grafana_dashboard.json

We've also updated several of the existing Grafana dashboards. As of 5.1.0, the dashboards are imported automatically during installation, but pre-5.1.0 you needed to import the dashboards manually. Please re-import the latest updates from: https://github.com/lucidworks/fusion-cloud-native/tree/master/monitoring/grafana

[[upgrade-to-502]]
== Upgrade from 5.0.1 to 5.0.2 to Zookeeper 3.5.6 and Solr 8.3.1

Fusion 5.0.1 (and subsequent 5.0.2 pre-release versions, such as 5.0.2-7) runs Solr 8.2.0 and Zookeeper 3.4.14.
Prior to upgrading to Fusion 5.0.2, you need to upgrade Solr to 8.3.1 in your existing cluster and perform some minor changes to the custom values yaml.

When you upgrade to 5.0.2, Zookeeper will migrate from 3.4.14 to 3.5.6. Behind the scenes, we also had update the ZK Helm chart to work around an issue with purging logs (https://github.com/kubernetes-retired/contrib/issues/2942),
so we'll have to delete the existing StatefulSet in order to switch charts during the upgrade.

Prior to upgrading, list our your releases for Helm v2:

```
helm ls --all-namespaces
```

Once you're ready to upgrade, on a Mac, do:
```
brew upgrade kubernetes-helm
```
For other OS, download from https://github.com/helm/helm/releases

Verify: helm version --short
```
v3.0.0+ge29ce2a
```

=== Migrate your release to Helm v3 using the helm-2to3 plugin (if needed)

If you installed your F5 cluster using Helm v2, you need to migrate it to v3 using the process described here:
https://helm.sh/blog/migrate-from-helm-v2-to-helm-v3/. Basically, you need to migrate the release metadata that lives in Tiller over to your local system.

If you installed your cluster with Helm v3 originally, then you don't need to do this step. Just verify your release is shown by: `helm ls`

During testing, we found upgrading Solr to 8.3.1 before moving to ZK 3.5.6 was more stable.

Edit your custom values yaml file and change the Solr version to 8.3.1.
```
solr:
  image:
    tag: 8.3.1
  updateStrategy:
    type: "RollingUpdate"
```

Determine the version of the Fusion chart you are currently running (shown by `helm ls -n <namespace>`) as you'll need to pass that to the setup script when upgrading Solr to 8.3.1.

For instance, your chart version may be: `fusion-5.0.2-7` in which case you would pass `--version 5.0.2-7`. The `-7` part of the version is considered a "pre-release" of 5.0.2 in the semantic versioning scheme, see: https://semver.org/

```
./setup_f5_gke.sh -c <existing_cluster> -p <gcp_project_id> -r <release> -n <namespace> \
  --version <CHART_VERSION> \
  --values gke_<cluster>_<release>_fusion_values.yaml --upgrade
```

__Wait until solr is back up and heatlhy__

*IMPORTANT: You need to edit your custom values file and move the Zookeeper settings out from under the `solr:` section to the main level, e.g. instead of:*

```
solr:
  ...
  zookeeper:
    ...
```

You need:
```
solr:
  ...

zookeeper:
  ...
```

At this point you're ready to switch over to ZK 3.5.6. However, we cannot do this with zero downtime, meaning your cluster will lose quorum momentarily.
So plan to have a minute or so of downtime in this cluster. Also, to avoid as much downtime as possible, be ready to upgrade to 5.0.2 immediately after deleting the existing statefulset.

When ready, do:

```
kubectl delete statefulset ${RELEASE}-solr
kubectl delete statefulset ${RELEASE}-zookeeper
```

Deleting the StatefulSet does not remove the persistent volumes backing Zookeeper and Solr, so no data will be lost.

After editing your custom values yaml file, run:

```
cd fusion-cloud-native

./setup_f5_gke.sh -c <CLUSTER> -p <PROJECT> -z <ZONE> \
  -n <NAMESPACE> -r <RELEASE> \
    --values <MY_VALUES> --version 5.0.2 --upgrade --force
```

Wait a few minutes and then verify the new ZK establishes quorum:

```
kubectl get pods
```

It will take some time for the upgrade to rollout across all the services as K8s needs to pull new Docker images and then perform a rolling upgrade for each Fusion service.

After upgrading, verify the versions of each pod:
```
kubectl get po -o jsonpath='{..image}'  | tr -s '[[:space:]]' '\n' | sort | uniq
```

=== Install Prometheus / Grafana to Existing Cluster

As of 5.0.2, the Fusion setup scripts provide the option to install Prometheus and Grafana using the `--prometheus` option.
However, if you installed a previous version of Fusion 5.0.x, then the upgrade does not install Prometheus / Grafana for you.

Once you complete the upgrade to Fusion 5.0.2, you can run the https://github.com/lucidworks/fusion-cloud-native/blob/master/install_prom.sh[install_prom.sh^] script to install these additional services into your namespace. Pass the `--help` option to see script usage details.

For instance, to install into a GKE cluster and schedule the new pods in the default Node Pool, you would do:
```
./install_prom.sh -c <cluster> -r <release> -n <namespace> \
  --node-pool "cloud.google.com/gke-nodepool: default-pool" --provider gke
```

Once Prometheus and Grafana are deployed, edit your custom values yaml file for Fusion to enable the Solr exporter:
```
solr:
  ...
  exporter:
    enabled: true
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9983"
      prometheus.io/path: "/metrics"
    nodeSelector:
      cloud.google.com/gke-nodepool: default-pool
```

Add pod annotations to the `query-pipeline`, `fusion-indexing`, `api-gateway` services as needed to allow Prometheus to scrape metrics:

```
fusion-indexing:
  ...
  pod:
    annotations:
      prometheus.io/port: "8765"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"
```

```
query-pipeline:
  ...
  pod:
    annotations:
      prometheus.io/port: "8787"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"
```

```
api-gateway:
  ...
  pod:
    annotations:
      prometheus.io/port: "6764"
      prometheus.io/scrape: "true"
      prometheus.io/path: "/actuator/prometheus"
```

After making changes to the custom values yaml file, run an upgrade on the Fusion Helm chart.

// end::body[]
